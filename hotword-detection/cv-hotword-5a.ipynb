{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5a: Hotword Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the solutions for hotword detection and to save the list of mp3 filenames with the hot words detected into a file ```detected.txt```\n",
    "\n",
    "Ensure to use the following file ```cv-valid-dev.csv``` to access the transcribed results of cv-valid-dev mp3 dataset with my fine-tuned model in task 4.\n",
    "\n",
    "```Note: The assumption of the hotwords is that we will use the exact word form to classify the word as a hotword```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import torch\n",
    "\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set Pandas display options to show full text\n",
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the ```cv-valid-dev.csv``` in task 2d contains the transcriptions from the original Wav2Vec2 model, I need to transcribe it differently with my fine-tuned model to generate the file required for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My Hugging Face Hub model name\n",
    "MY_MODEL_NAME = \"enlihhhhh/wav2vec2-large-960h-cv\"\n",
    "\n",
    "# Load the fine-tuned model and processor\n",
    "processor = Wav2Vec2Processor.from_pretrained(MY_MODEL_NAME)\n",
    "model = Wav2Vec2ForCTC.from_pretrained(MY_MODEL_NAME)\n",
    "\n",
    "# Move model to GPU if available\n",
    "model.to(device)\n",
    "\n",
    "def transcribe_audio(audio_path):\n",
    "    try:\n",
    "        # Read the audio file\n",
    "        audio, sample_rate = sf.read(f\"../asr/data/{audio_path}\")\n",
    "\n",
    "        # Resample if not already 16kHz\n",
    "        if sample_rate != 16000:\n",
    "            audio = librosa.resample(audio, orig_sr=sample_rate, target_sr=16000)\n",
    "\n",
    "        # Convert audio to tensor and move to same device as model\n",
    "        input_values = processor(audio, return_tensors=\"pt\", sampling_rate=16000).input_values.to(device)\n",
    "\n",
    "        # Perform inference\n",
    "        with torch.no_grad():\n",
    "            logits = model(input_values).logits\n",
    "\n",
    "        # Decode the logits\n",
    "        predicted_ids = torch.argmax(logits, dim=-1)\n",
    "        transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "        return transcription\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error transcribing {audio_path}: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing Audio Files: 100%|██████████| 4076/4076 [01:03<00:00, 63.98it/s]\n"
     ]
    }
   ],
   "source": [
    "# Assuming that your asr folder contains the common voice dataset\n",
    "dev_common_voice = pd.read_csv(\"data/cv-valid-dev.csv\")\n",
    "dev_common_voice = dev_common_voice[['filename']]\n",
    "\n",
    "# Call the transcribe function\n",
    "tqdm.pandas(desc=\"Transcribing Audio Files\")\n",
    "dev_common_voice[\"generated_text\"] = dev_common_voice[\"filename\"].progress_apply(transcribe_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>generated_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cv-valid-dev/sample-000000.mp3</td>\n",
       "      <td>be careful with your propnastigations said the stranger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cv-valid-dev/sample-000001.mp3</td>\n",
       "      <td>then why should they be surprised when they se born</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cv-valid-dev/sample-000002.mp3</td>\n",
       "      <td>a young arab also loaded down with bagage entered and greted the englishman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cv-valid-dev/sample-000003.mp3</td>\n",
       "      <td>i felt that everything i owned would be destroyed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cv-valid-dev/sample-000004.mp3</td>\n",
       "      <td>he moved about invisible but everyone could hear him</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         filename  \\\n",
       "0  cv-valid-dev/sample-000000.mp3   \n",
       "1  cv-valid-dev/sample-000001.mp3   \n",
       "2  cv-valid-dev/sample-000002.mp3   \n",
       "3  cv-valid-dev/sample-000003.mp3   \n",
       "4  cv-valid-dev/sample-000004.mp3   \n",
       "\n",
       "                                                                generated_text  \n",
       "0                      be careful with your propnastigations said the stranger  \n",
       "1                          then why should they be surprised when they se born  \n",
       "2  a young arab also loaded down with bagage entered and greted the englishman  \n",
       "3                            i felt that everything i owned would be destroyed  \n",
       "4                         he moved about invisible but everyone could hear him  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lowercase the generated text\n",
    "dev_common_voice[\"generated_text\"] = dev_common_voice[\"generated_text\"].str.lower()\n",
    "dev_common_voice.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we define the hot words ```be careful, destroy, stranger``` to detect following the assumption defined at the top of this notebook.\n",
    "\n",
    "Based on the assumption, I will list cases where words will not be classified as hot words:\n",
    "1. destroyed != destroy\n",
    "2. becareful != be careful\n",
    "3. strange != stranger\n",
    "\n",
    "```Hence, we only match the exact words with the transcriptions.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The audio files that contain the hotwords are:\n",
      "['cv-valid-dev/sample-000000.mp3', 'cv-valid-dev/sample-000003.mp3', 'cv-valid-dev/sample-000089.mp3', 'cv-valid-dev/sample-000508.mp3', 'cv-valid-dev/sample-000674.mp3', 'cv-valid-dev/sample-001093.mp3', 'cv-valid-dev/sample-001101.mp3', 'cv-valid-dev/sample-001243.mp3', 'cv-valid-dev/sample-001501.mp3', 'cv-valid-dev/sample-001933.mp3', 'cv-valid-dev/sample-002405.mp3', 'cv-valid-dev/sample-002453.mp3', 'cv-valid-dev/sample-003065.mp3', 'cv-valid-dev/sample-003219.mp3', 'cv-valid-dev/sample-003808.mp3']\n"
     ]
    }
   ],
   "source": [
    "# Define the target hotwords\n",
    "hotwords = [\"be careful\", \"destroy\", \"stranger\"]\n",
    "\n",
    "# Find the matching audio filenames that contain the hotwords in the transcribed results\n",
    "target_files = dev_common_voice[dev_common_voice[\"generated_text\"].str.contains(\"|\".join(hotwords), case=False, na=False)][\"filename\"]\n",
    "\n",
    "# Convert the target_files Series to a list\n",
    "audio_files_list = target_files.tolist()\n",
    "print(\"The audio files that contain the hotwords are:\")\n",
    "print(audio_files_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The audio filenames have been saved to detected.txt file\n"
     ]
    }
   ],
   "source": [
    "# Now, we save the filenames into a .txt file\n",
    "with open(\"detected.txt\", \"w\") as f:\n",
    "    for file in audio_files_list:\n",
    "        f.write(file + \"\\n\")\n",
    "print(\"The audio filenames have been saved to detected.txt file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the transcribed results to a CSV file\n",
    "dev_common_voice.to_csv(\"cv-valid-dev.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "htx_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
